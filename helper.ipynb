{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from backdoor.defense import FoolsGold\n",
    "import torch\n",
    "\n",
    "name = \"foolsgold\"\n",
    "memory_size = 0\n",
    "\n",
    "defender = FoolsGold(name)\n",
    "state_dict_list = torch.load(\"/root/autodl-tmp/GitRepos/BackdoorFIT/output/natural_instruction_20000_fedavg_c5s5_i40_b4a1_l1024_r128a256_pTruenbadnetspcr0.1pr0.1_2024-05-20_11-30-38/locals/local_dict_list_30.pth\")\n",
    "local_state_list = state_dict_list[:-1]\n",
    "global_state = state_dict_list[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START Aggregating history of gradient directions\n",
      "wv: [0.34245991 0.71251132 0.34245991 0.72634877 1.        ]\n",
      "[0.10962997 0.22809268 0.10962997 0.23252239 0.32012498]\n"
     ]
    }
   ],
   "source": [
    "from utils import flatten_dict\n",
    "import numpy as np \n",
    "\n",
    "key_order = global_state.keys()\n",
    "total_params = sum(p.numel() for p in global_state.values())\n",
    "clients_this_round = list(range(len(local_state_list)))\n",
    "\n",
    "flatten_global_model = flatten_dict(global_state, key_order)\n",
    "delta = np.zeros((len(local_state_list), total_params))\n",
    "summed_deltas = np.zeros((len(local_state_list), total_params))\n",
    "\n",
    "for client_idx in range(len(local_state_list)):\n",
    "    flatten_local_model = flatten_dict(local_state_list[client_idx], key_order)\n",
    "    local_update = flatten_local_model - flatten_global_model\n",
    "    local_update = local_update.detach().cpu().numpy()\n",
    "    delta[client_idx,:] = local_update\n",
    "# normalize delta\n",
    "    if np.linalg.norm(delta[client_idx, :]) > 1:\n",
    "        delta[client_idx, :] = delta[client_idx, :] / np.linalg.norm(delta[client_idx, :])\n",
    "\n",
    "    summed_deltas[clients_this_round,:] = summed_deltas[clients_this_round,:] + delta[clients_this_round,:]\n",
    "\n",
    "n_freq = defender(delta[clients_this_round,:], summed_deltas[clients_this_round, :], global_state, round, \"0\", len(local_state_list), total_params, key_order)\n",
    "print(n_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START Aggregating history of gradient directions\n",
      "wv: [0.50874185 1.         0.50874185 0.54659196 0.54659196]\n",
      "5 [0.16354748 0.3214744  0.16354748 0.17571532 0.17571532]\n",
      "START Aggregating history of gradient directions\n",
      "wv: [0.59609011 1.         0.57768263 0.59609011 0.57768263]\n",
      "10 [0.17806782 0.29872634 0.17256902 0.17806782 0.17256902]\n",
      "START Aggregating history of gradient directions\n",
      "wv: [0.34245991 0.71251132 0.34245991 0.72634877 1.        ]\n",
      "15 [0.10962997 0.22809268 0.10962997 0.23252239 0.32012498]\n",
      "START Aggregating history of gradient directions\n",
      "wv: [0.5477578 0.5449403 1.        0.5477578 0.5449403]\n",
      "20 [0.17195908 0.17107458 0.31393269 0.17195908 0.17107458]\n",
      "START Aggregating history of gradient directions\n",
      "wv: [0.37817432 0.05710702 1.         0.37817432 0.05710702]\n",
      "25 [0.20217142 0.03052933 0.5345985  0.20217142 0.03052933]\n",
      "START Aggregating history of gradient directions\n",
      "wv: [0.6627964  0.23792905 0.23792905 1.         0.6627964 ]\n",
      "30 [0.2365904  0.08493065 0.08493065 0.35695789 0.2365904 ]\n",
      "START Aggregating history of gradient directions\n",
      "wv: [1.         0.50865103 1.         0.44653488 0.44653488]\n",
      "35 [0.29396886 0.14952757 0.29396886 0.13126735 0.13126735]\n"
     ]
    }
   ],
   "source": [
    "from backdoor.defense import FoolsGold\n",
    "import torch\n",
    "\n",
    "name = \"foolsgold\"\n",
    "memory_size = 0\n",
    "\n",
    "rounds = [5, 10, 15, 20, 25, 30, 35]\n",
    "defender = FoolsGold(name)\n",
    "\n",
    "for round in rounds:\n",
    "\n",
    "    state_dict_list = torch.load(f\"/root/autodl-tmp/GitRepos/BackdoorFIT/output/natural_instruction_20000_fedavg_c5s5_i40_b4a1_l1024_r128a256_pTruenbadnetspcr0.1pr0.1_2024-05-20_11-30-38/locals/local_dict_list_{round}.pth\")\n",
    "    local_state_list = state_dict_list[:-1]\n",
    "    global_state = state_dict_list[-1]\n",
    "    \n",
    "    \n",
    "    from utils import flatten_dict\n",
    "    import numpy as np \n",
    "\n",
    "    key_order = global_state.keys()\n",
    "    total_params = sum(p.numel() for p in global_state.values())\n",
    "    clients_this_round = list(range(len(local_state_list)))\n",
    "\n",
    "    flatten_global_model = flatten_dict(global_state, key_order)\n",
    "    delta = np.zeros((len(local_state_list), total_params))\n",
    "    summed_deltas = np.zeros((len(local_state_list), total_params))\n",
    "\n",
    "    for client_idx in range(len(local_state_list)):\n",
    "        flatten_local_model = flatten_dict(local_state_list[client_idx], key_order)\n",
    "        local_update = flatten_local_model - flatten_global_model\n",
    "        local_update = local_update.detach().cpu().numpy()\n",
    "        delta[client_idx,:] = local_update\n",
    "# normalize delta\n",
    "        if np.linalg.norm(delta[client_idx, :]) > 1:\n",
    "            delta[client_idx, :] = delta[client_idx, :] / np.linalg.norm(delta[client_idx, :])\n",
    "\n",
    "        summed_deltas[clients_this_round,:] = summed_deltas[clients_this_round,:] + delta[clients_this_round,:]\n",
    "\n",
    "    n_freq = defender(delta[clients_this_round,:], summed_deltas[clients_this_round, :], global_state, round, \"0\", len(local_state_list), total_params, key_order)\n",
    "    print(round, n_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics.pairwise as smp\n",
    "cs = smp.cosine_similarity(summed_deltas) - np.eye(len(local_state_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4225066397320916e-13 0.00032732961575713973 0.44669911814154023 0.4759983418993628 0.3949878837597612\n",
      "0.00032732961575713973 0.0 0.0002412932601735299 0.0003475241320809415 0.0003179499799409736\n",
      "0.44669911814154023 0.0002412932601735299 0.0 0.44443827802898817 0.48059154841785146\n",
      "0.4759983418993628 0.0003475241320809415 0.44443827802898817 3.752553823233029e-14 0.4099465358149259\n",
      "0.3949878837597612 0.0003179499799409736 0.48059154841785146 0.4099465358149259 0.0\n"
     ]
    }
   ],
   "source": [
    "cs[cs<0] = 0\n",
    "cs[cs>1] = 1\n",
    "for i in range(5):\n",
    "    print( cs[i, 0], cs[i, 1],cs[i, 2],cs[i, 3],cs[i, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3862e-03, -3.3944e-04,  2.4185e-04,  ..., -3.6904e-04,\n",
       "          9.4480e-04, -8.7129e-04],\n",
       "        [ 7.3853e-04,  5.8428e-04,  8.1919e-04,  ..., -2.4954e-04,\n",
       "         -1.3643e-03,  1.3407e-04],\n",
       "        [ 1.9449e-03, -6.3301e-04,  1.2600e-03,  ..., -1.3771e-03,\n",
       "          4.2716e-04, -1.2013e-03],\n",
       "        ...,\n",
       "        [ 5.7995e-04, -1.4022e-04,  8.3167e-04,  ...,  7.9757e-05,\n",
       "          1.2993e-03, -1.3064e-04],\n",
       "        [ 8.7260e-04,  6.0580e-05,  8.5691e-04,  ..., -2.0073e-04,\n",
       "          2.3117e-03,  1.1648e-03],\n",
       "        [-2.4665e-04, -1.0497e-04,  3.5607e-04,  ..., -5.7412e-04,\n",
       "          1.7794e-04, -6.4561e-04]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "before_data_pth = torch.load(\"/home/zx/nas/GitRepos/BackdoorFIT/test/tmp/before_edit_weight.pth\")\n",
    "\n",
    "before_data_pth[\"model.layers.9.mlp.down_proj.lora_B.weight\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3862e-03, -3.3944e-04,  2.4185e-04,  ..., -3.6904e-04,\n",
       "          9.4480e-04, -8.7129e-04],\n",
       "        [ 7.3853e-04,  5.8428e-04,  8.1919e-04,  ..., -2.4954e-04,\n",
       "         -1.3643e-03,  1.3407e-04],\n",
       "        [ 1.9449e-03, -6.3301e-04,  1.2600e-03,  ..., -1.3771e-03,\n",
       "          4.2716e-04, -1.2013e-03],\n",
       "        ...,\n",
       "        [ 5.7995e-04, -1.4022e-04,  8.3167e-04,  ...,  7.9757e-05,\n",
       "          1.2993e-03, -1.3064e-04],\n",
       "        [ 8.7260e-04,  6.0580e-05,  8.5691e-04,  ..., -2.0073e-04,\n",
       "          2.3117e-03,  1.1648e-03],\n",
       "        [-2.4665e-04, -1.0497e-04,  3.5607e-04,  ..., -5.7412e-04,\n",
       "          1.7794e-04, -6.4561e-04]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "after_data_pth = torch.load(\"/home/zx/nas/GitRepos/BackdoorFIT/test/tmp/after_edit_weight.pth\")\n",
    "\n",
    "after_data_pth[\"model.layers.9.mlp.down_proj.lora_B.weight\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
